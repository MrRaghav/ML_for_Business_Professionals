Embedding Projector to understand what models learn about data without being told.

--------------
TensorBoardâ€™s Embedding Projector is a tool designed for this purpose.
-------------

In this lab, we will examine how a model trained to work with text groups the meanings of words. 
The model has learned about these relationships solely by looking at documents and seeing which groups of words tend to occur together.


Steps
*****
Step 1 The Embedding Projector Interface: https://projector.tensorflow.org/

The Embedding Projector has five panels:

    Data panel on the top left, where you can choose the dataset to examine
    Projections panel on the bottom left, which can be used, among other things, to define how to orient the visualization
    Inspector panel on the top right, where you can search for particular points--in this case, words--and see a list of nearest neighbors
    Bookmarks panel, on the bottom right, displays saved sets of parameters for the tool
    Visualization panel in the center, where the data are displayed

Step 2 Exploring Learned Relationships part 1
    
    One of the most basic sanity checks for understanding what a model has learned is to do a neighborhood analysis. 
    A neighborhood analysis involves looking at the nearest neighbors for a set of predefined data points and seeing if they make intuitive sense.

Step 3 Exploring Learned Relationships part 2

    The Embedding Projector also allows you also re-orient the visualization, 
    in order to do more sophisticated tests for these cases and we will use this to demonstrate how a model 
    has learned that male words are more related to math while female words are more related to art

    